# Практика 3: Оптимизация работы с памятью

## Цели

__Цель данной работы__ — научиться ускорять время работы алгоритма за счет более
эффективной организации работы с памятью. В частности, в рамках этого
практического задания мы попытаемся избавиться от ненужных доступов к памяти,
плюс познакомимся с такой техникой как look-up table (LUT).

## Задачи

__Основные задачи__

  1. Научиться измерять и сравнивать время работы/производительность различных
     реализаций одного алгоритма.
  1. Познакомиться с измерением производительности алгоритмов, время работы
     которых зависит от данных.
     - Что произойдет, если в предложенном тесте убрать инициализацию генератора
       случайных чисел фиксированным значением? Можно ли так поступить?
     - Является ли предложенный тест производительности хорошим?
  1. Применить две базовые техники оптимизации:
     - минимизация числа операций;
     - кэширование вычислений.
  1. Сравнить эффект от применения двух предложенных оптимизаций по-отдельности
     и совместно.

__Дополнительные задачи__

  - Разобраться с зависимостью времени работы алгоритма от данных. Добавить
    тесты для лучшего и худшего случая.
  - Выяснить, какой порядок загрузки значений соседних пикселей является
    наиболее эффективным. Объяснить почему.
  - (Домашнее задание). В случае изображения размера NxN, предложенная
    реализация алгоритма имеет оценку вычислительной сложности в худшем случае
    `O(N^3)`. Возможна реализация с оценкой `O(N^2)`. Предложить такую
    реализацию, сравнить производительность.

## Общая последовательность действий

  1. Получить актуальное состояние ветки `master` из
     [upstream][upstream]-репозитория. Собрать проект и проверить его
     работоспособность, запустив тесты и демо-приложение.

  1. Создать новую ветку в Git для выполнения практического задания. Изменения
     необходимо постоянно фиксировать в истории Git, выкладывая в рабочую ветку
     на GitHub и контролируя успешность тестирования на Travis-CI.

  1. Запустить тесты производительности для функции `GuoHallThinning` и
     сохранить XML-файл с результатами. Этот файл в дальнейшем будет использован
     для сравнения производительности до и после оптимизации.

  1. Разобраться с алгоритмом `GuoHallThinning` и оптимизировать его, используя
     следующие приемы:
     - минимизация числа операций, особенно обращений к памяти;
     - кэширование вычислений.

  1. Убедиться, что оптимизированная функция работает быстрее, чем оригинальный
     код. Это следует сделать путем сравнения отчетов о производительности. При
     этом результат работы оптимизированной функции должен полностью совпадать с
     результатом исходной версии.

## Детальная инструкция по выполнению работы

Прежде чем приступить к выполнению работы, следует получить актуальное состояние
проекта из центрального репозитория. Для этого можно воспользоваться
[инструкциями][git-update] из второго практического задания.

Тесты, разработанные на прошлом занятии, не обязательны. Вы можете добавить их в
проект, но можно будет обойтись и без них.

### Сбор первоначальных метрик производительности

  1. Убедитесь, что проект собран в __`Release`__ конфигурации!

  1. Тесты производительности находятся в сборке `perf_skeleton`, и для их
     запуска достаточно запустить это приложение. Тесты производительности
     __не печатают__ времена работы функций в консольном выводе:

     ```bash
     $ cd itseez-ws-2016-practice-build
     $ ./bin/perf_skeleton
     ```

  1. Для того, чтобы сохранить результаты измерения производительности,
     необходимо передать тестовому фреймворку имя файла для записи
     разельтатов текущего запуска:

     ```bash
     $ ./bin/perf_skeleton --gtest_output=xml:base.xml
     ```

  1. Для просмотра производительности одного эксперимента можно
     использовать скрипт `report.py`, являющегося частью тестового фреймворка:

     ```bash
     $ python ../itseez-ws-2016-practice/3rdparty/opencv_ptest/misc/report.py base.xml -c gmean,min,samples
     ```

     ```txt
              Name of Test          Geometric mean    Min         Number of
                                                              collected samples
     Thinning::Size_Only::1280x720    831.34 ms    824.14 ms         49
     Thinning::Size_Only::1920x1080   2422.72 ms   2400.85 ms        17
     Thinning::Size_Only::640x480     340.01 ms    336.50 ms         100
     ```

  1. Для сравнения производительности нескольких версий можно использовать
     скрипт `summary.py`:

     ```bash
     $ python ../itseez-ws-2016-practice/3rdparty/opencv_ptest/misc/summary.py base.xml optimized.xml
     ```

     ```txt
              Name of Test             base      optimized  optimized
                                                                vs
                                                               base
                                                            (x-factor)
     Thinning::Size_Only::640x480   340.009 ms  143.618 ms     2.37
     Thinning::Size_Only::1280x720  831.337 ms  362.249 ms     2.29
     Thinning::Size_Only::1920x1080 2422.718 ms 1057.336 ms    2.29
     ```

  1. Для ускорения проведения экспериментов можно исключить не относящиеся
     к оптимизируемой функции тесты, используя фильтр:

     ```bash
     $ ./bin/perf_skeleton --gtest_output=xml:optimized.xml --gtest_filter=*Thinning*
     ```

### Оптимизация производительности

  1. Применение "первого" приема оптимизации — избегание ненужных обращений к
     памяти и вычислений. Обратите внимание на следующее свойство алгоритма:
     если какой-либо из пикселей обратился в ноль, то он уже никогда не станет
     ненулевым. Значит, в функции `GuoHallIteration` для пикселей с нулевым
     значением можно не проверять соседей. Реализуйте данное упрощение и
     сохраните новый отчет о производительности, сравните его с базовой версией.

  1. Применение "второго" приёма оптимизации - кэширование вычислений:

     1. Тот факт, что функция работает с бинарным изображением, позволяет
        взаимооднозначно закодировать значения всех соседей пикселя используя
        всего 1 байт. Например окрестность вида:

        ```txt
        1 0 1
        1 . 0
        1 0 1
        ```

        можно представить в бинарном виде как `10110101` (181 в десятичной
        записи). Таким образом, всего существует 256 вариантов для окрестности
        любой точки, и любой вариант можно упаковать в байт. То есть фактически
        нужно построить таблицу, которая в любому байту (исходное значение
        пикселов окрестности) ставила бы в соответствие ноль или единицу (новое
        значение пикселя).

        Применительно к данной задаче, кодирование может выглядеть следующим
        образом:

        ```cpp
        // Pixel neighbourhood structure
        // p9 p2 p3
        // p8 p1 p4
        // p7 p6 p5

        // Encode neghbourhood pixel values to byte
        code = p2 * 1 +
               p3 * 2 +
               p4 * 4 +
               p5 * 8 +
               p6 * 16 +
               p7 * 32 +
               p8 * 64 +
               p9 * 128;

        // Decode byte (index in LUT) to neighbourhood pixel values
        p2 = code & 1;
        p3 = code & 2;
        p4 = code & 4;
        p5 = code & 8;
        p6 = code & 16;
        p7 = code & 32;
        p8 = code & 64;
        p9 = code & 128;

        ```

     1. Итак, логику обработки одной точки в функции `GuoHallIteration` можно
        заменить на логику кодирования ее окрестности в байт, и поиска в заранее
        подготовленной таблице (look-up table). Фактически, байт нужно
        использовать как индекс в таблице, значением же в таблице должны
        являться 0 или 1, которые есть новое значение пикселя. Вам необходимо
        реализовать описанную процедуру с целью получения ускорения.

        Подсказки:

        - Логика преобразования зависит от параметра `iter`, так что необходимо
          будет подготовить две таблицы.
        - Время построения таблиц пренебрежимо мало в сравнении с основным
          алгоритмом. Можно пересоздавать таблицы при каждом вызове функции.
        - Порядок загрузки значений соседних пикселей может незначительно влиять
          на скорость выполнения кода.
        - Не стоит тратить время на оптимизацию вычислений в функции
          `GuoHallIteration` — это не перспективное направление.
        - Функцию можно переписать так, чтобы избежать копирований, операций
          применения маски и конверсии значений 255 в 1 и обратно, но затраты на
          все эти операции меньше, чем эффект от оптимизаций предложенных в
          описании выше.

После того, как вы выполните основные задачи, можете обратиться к
дополнительным. На практике мы осуществляли оптимизации, в целом сохраняющие
алгоритм и его сложность. Однако возможна и алгоритмическая оптимизация,
позволяющая дополнительно ускорить время работы.

<!-- LINKS -->

[git-update]: https://github.com/itseez-academy/itseez-ws-2016-practice/blob/master/docs/practice2-profiling-and-benchmarking.md#Получение-актуальной-версии-исходных-файлов
[upstream]:   https://github.com/itseez-academy/itseez-ws-2016-practice
